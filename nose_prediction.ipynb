{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as plt\n",
    "import numpy as np\n",
    "import argparse\n",
    "import os\n",
    "from tqdm.notebook import tqdm as tqdm\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from jax.experimental.optimizers import adam\n",
    "from jax.experimental.stax import *\n",
    "from jax import random, jit\n",
    "import numpy as np\n",
    "import glob\n",
    "from skimage.transform import resize\n",
    "from livelossplot import PlotLosses\n",
    "\n",
    "from utils.img_ops import *\n",
    "from utils import *\n",
    "\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision.transforms import Compose, ColorJitter, Resize, ToTensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImmFaceDb(Dataset):\n",
    "    def __init__(self, root_dir, keypoints=[-6], transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_file (string): Path to the csv file with annotations.\n",
    "            root_dir (string): Directory with all the images.\n",
    "        \"\"\"\n",
    "        self.root_dir = root_dir\n",
    "        img_paths = glob.glob(root_dir + '/*.png')\n",
    "        img_paths.sort()\n",
    "        self.img_paths = np.array(img_paths)\n",
    "\n",
    "        asf_paths = glob.glob(root_dir + '/*.asf')\n",
    "        asf_paths.sort()\n",
    "        self.asf_paths = np.array(asf_paths)\n",
    "\n",
    "        self.keypoints = keypoints\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_paths)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_paths = self.img_paths[idx]\n",
    "        asf_paths = self.asf_paths[idx]\n",
    "        \n",
    "        imgs = np.array([read(i, color=False) for i in img_paths])\n",
    "        imgs = imgs - 0.5\n",
    "        asf_data = [self.read_asf(f, self.keypoints) for f in asf_paths]\n",
    "        asf_data = np.row_stack([np.column_stack((x[0], x[1])) for x in asf_data])\n",
    "        sample = {'x': imgs, 'y': asf_data}\n",
    "\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "\n",
    "        return sample\n",
    "\n",
    "    def read_asf(self, file, keypoints=None):\n",
    "        \"\"\"Reads x, y points from asf file\n",
    "\n",
    "        Args:\n",
    "            file (str): path to asf file\n",
    "\n",
    "        Returns:\n",
    "            np.ndarray, np.ndarray: list of x points, list of y points\n",
    "        \"\"\"\n",
    "        if keypoints:\n",
    "            data = np.genfromtxt(file, skip_header=16, skip_footer=1, usecols=(2, 3))[keypoints, :]\n",
    "        else:\n",
    "            data = np.genfromtxt(file, skip_header=16, skip_footer=1, usecols=(2, 3))[:, :]\n",
    "        return data[:, 0], data[:, 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ColorJitterX(object):\n",
    "    def __call__(self, sample):\n",
    "        image, points = sample['x'], sample['y']\n",
    "        plt.imshow(image)\n",
    "        plt.show()\n",
    "        brightness = np.random.random() * 2 - 1\n",
    "        contrast = np.random.random() * 2 - 1\n",
    "        image = image * contrast + brightness\n",
    "        plt.imshow(image)\n",
    "        plt.show()\n",
    "        return {'x': image, 'y': points}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "batch_size = 8\n",
    "transforms = Compose([\n",
    "    Resize((240, 180)),\n",
    "    ColorJitterX(),\n",
    "])\n",
    "keypoints_dataset = ImmFaceDb('imm_face_db/', keypoints=None, transform=transforms)\n",
    "data_loader = DataLoader(keypoints_dataset, batch_size=batch_size, shuffle=False)\n",
    "print(list(data_loader))\n",
    "for i_batch, sample_batched in enumerate(data_loader):\n",
    "    print('hello')\n",
    "    plt.imshow(sample_batched['x'][0])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data\n",
    "val_split = (32, 8)\n",
    "train_imgs, train_points, val_imgs, val_points = load_data(\n",
    "    val_split=val_split, keypoints=[-6]\n",
    ")\n",
    "img = train_imgs[0]\n",
    "h, w, c = img.shape[0], img.shape[1], img.shape[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_init_fn, model = serial(\n",
    "    Conv(32, (3, 3), padding=\"SAME\"),\n",
    "    MaxPool((2, 2)),\n",
    "    Relu,\n",
    "    Conv(32, (3, 3), padding=\"SAME\"),\n",
    "    MaxPool((2, 2)),\n",
    "    Relu,\n",
    "    Conv(32, (3, 3), padding=\"SAME\"),\n",
    "    MaxPool((2, 2)),\n",
    "    Relu,\n",
    "    Flatten, \n",
    "    Dense(256),\n",
    "    Relu,\n",
    "    Dense(2)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss -- MSE\n",
    "@jit\n",
    "def loss_fn(params, imgs, gt):\n",
    "    pred = model(params, imgs)\n",
    "    return np.mean((pred - gt) ** 2)\n",
    "\n",
    "@jit\n",
    "def update(step, opt_state, imgs, gt):\n",
    "    value, grads = jax.value_and_grad(loss_fn)(opt.params_fn(opt_state), imgs, gt)\n",
    "    opt_state = opt.update_fn(step, grads, opt_state)\n",
    "    return value, opt_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Initialize Model\n",
    "batch_size = 16\n",
    "rng = random.PRNGKey(32)\n",
    "input_shape, params = model_init_fn(rng, (batch_size, h, w, c))\n",
    "\n",
    "# Optimizer\n",
    "lr = 1e-3\n",
    "opt = adam(lr)\n",
    "opt_state = opt.init_fn(params)\n",
    "\n",
    "# Create Plots\n",
    "plt_groups = {'loss':[]}\n",
    "plotlosses_model = PlotLosses(groups=plt_groups)\n",
    "plt_groups['loss'].append('nose_pred_train')\n",
    "plt_groups['loss'].append('nose_pred_val')\n",
    "\n",
    "# Training Loop\n",
    "epochs = 5\n",
    "steps = int(len(train_points) // batch_size)\n",
    "val_ratio = int(len(train_points) // len(val_points))\n",
    "\n",
    "train_loss = np.ndarray(steps * epochs)\n",
    "val_loss = np.ndarray(steps * epochs // val_ratio)\n",
    "\n",
    "iters = 0\n",
    "save_params = params\n",
    "min_val = 10000\n",
    "for j in tqdm(range(epochs), leave=False, desc='iter'):\n",
    "    for i in range(steps):\n",
    "        value, opt_state = update(\n",
    "            i,\n",
    "            opt_state,\n",
    "            train_imgs[i : i + batch_size],\n",
    "            train_points[i : i + batch_size],\n",
    "        )\n",
    "\n",
    "        plotlosses_model.update({'nose_pred_train':value}, current_step=iters)\n",
    "\n",
    "        # get validation loss\n",
    "        if i % val_ratio == 0:\n",
    "            val_value, grads = jax.value_and_grad(loss_fn)(\n",
    "                opt.params_fn(opt_state),\n",
    "                val_imgs,\n",
    "                val_points,\n",
    "            )\n",
    "            plotlosses_model.update({'nose_pred_val':val_value}, current_step=iters)\n",
    "            plotlosses_model.send()\n",
    "            \n",
    "            if val_value <= min_val:\n",
    "                save_params = opt.params_fn(opt_state)\n",
    "                min_val = val_value\n",
    "                \n",
    "        iters += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(3):\n",
    "    pred = model(save_params, val_imgs[i][None,...])\n",
    "    print(pred, val_points[i])\n",
    "    plt.imshow(val_imgs[i] + 0.5, cmap='gray')\n",
    "    plt.scatter(val_points[i][0] * w, val_points[i][1] * h)\n",
    "    plt.scatter(pred[i][0] * w, pred[i][1] * h)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(3):\n",
    "    pred = model(opt.params_fn(opt_state), train_imgs[i][None,...])\n",
    "    print(pred, val_points[i])\n",
    "    plt.imshow(train_imgs[i] + 0.5, cmap='gray')\n",
    "    plt.scatter(train_points[i][0] * w, train_points[i][1] * h)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plotlosses_model.send()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
